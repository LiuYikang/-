## python垃圾回收机制
引用计数

### python 内存泄漏场景
1. 对象被另一个生命周期特别长的对象所引用，比如网络服务器，可能存在一个全局的单例ConnectionManager，管理所有的连接Connection，如果当Connection理论上不再被使用的时候，没有从ConnectionManager中删除，那么就造成了内存泄露。
2. 循环引用中的对象定义了__del__函数，这个在[程序员必知的Python陷阱与缺陷列表](http://www.cnblogs.com/xybaby/p/7183854.html)一文中有详细介绍，简而言之，如果定义了__del__函数，那么在循环引用中Python解释器无法判断析构对象的顺序，因此就不错处理。

## python闭包
https://foofish.net/python-closure.html

## 迭代器和生成器
生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是全部存在内存里,它们只在要调用的时候在内存里生成

生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4

Yield的用法和关键字return差不多,返回一个生成器

当for语句第一次调用函数里返回的生成器对象,函数里的代码就开始运作,直到碰到yield,然后会返回本次循环的第一个返回值.所以下一次调用也将运行一次循环然后返回下一个值,直到没有值可以返回.

一旦函数运行并且没有碰到yeild语句就认为生成器已经为空了.原因有可能是循环结束或者没有满足if/else之类的.

## 重写__new__函数会出现什么问题

## python描述符

## map的底层实现

## 多线程GIL
GIL是全局线程锁，因为GIL的存在，python无法实现真正的多线程。

如果是CPU密集型操作，GIL导致多线程无法提高效率；如果是IO密集型操作，多线程可以根据任务的IO等待进行CPU工作的切换。

多核CPU也无法解决GIL导致的线程问题，在多核的情况下，使用多进程是提高CPU利用的方法。
